{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6c7e849a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-11T09:24:53.643384Z",
     "start_time": "2021-06-11T09:24:53.622385Z"
    }
   },
   "source": [
    "# Classification Predict Student Solution\n",
    "\n",
    "© Explore Data Science Academy\n",
    "\n",
    "---\n",
    "### Honour Code\n",
    "\n",
    "We **TEAM-CW3**, confirm - by submitting this document - that the solutions in this notebook are a result of our own work and that we abide by the [EDSA honour code](https://drive.google.com/file/d/1QDCjGZJ8-FmJE3bZdIQNwnJyQKPhHZBn/view?usp=sharing).\n",
    "\n",
    "Non-compliance with the honour code constitutes a material breach of contract.\n",
    "\n",
    "### Predict Overview: Climate Change Belief Analysis Challenge\n",
    "\n",
    "Many companies are built around lessening one’s environmental impact or carbon footprint. They offer products and services that are environmentally friendly and sustainable, in line with their values and ideals. They would like to determine how people perceive climate change and whether or not they believe it is a real threat or not. This would add to their market research efforts in gauging how their product/service may be received. The sentiments are classified numerically, see below for their meaning:\n",
    "\n",
    "### Sentiment value: Sentiment description\n",
    "* 2 News: the tweet links to factual news about climate change\n",
    "* 1 Pro: the tweet supports the belief of man-made climate change\n",
    "* 0 Neutral: the tweet neither supports nor refutes the belief of man-made climate change\n",
    "* -1 Anti: the tweet does not believe in man-made climate change\n",
    "\n",
    "- 1. analyse the supplied data;\n",
    "- 2. identify potential errors in the data and clean the existing data set;\n",
    "- 3. determine if additional features can be added to enrich the data set;\n",
    "- 4. build a model that is capable of classifying people's belief when is comes to carbon threat by products;\n",
    "- 5. evaluate the accuracy of the best machine learning model;\n",
    "- 6. determine what features were most important in the model’s prediction decision, and\n",
    "- 7. explain the inner working of the model to a non-technical audience.\n",
    "\n",
    "Formally the problem statement is given to CW3 by, the senior data scientist (Claudia Wilson), via email reads as follow:\n",
    "\n",
    "> In this project Explore Data Science Academy's TEAM-CW3 is tasked to solve this challenge by creating an Advanced Classification Machine Learning model that is able to classify whether or not a person believes in climate change, based on their novel tweet data.\n",
    " \n",
    "Additionally we provide these companies with notebook containing explanations of what the main outcomes are. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05600c92",
   "metadata": {},
   "source": [
    "<a id=\"cont\"></a>\n",
    "\n",
    "## Table of Contents\n",
    "\n",
    "<a href=#one>1. Importing Packages</a>\n",
    "\n",
    "<a href=#two>2. Loading Data</a>\n",
    "\n",
    "<a href=#three>3. Exploratory Data Analysis (EDA)</a>\n",
    "\n",
    "<a href=#four>4. Sentiment Analysis</a>\n",
    "\n",
    "<a href=#five>5. Modeling</a>\n",
    "\n",
    "<a href=#six>6. Model Performance</a>\n",
    "\n",
    "<a href=#seven>7. Model Explanations</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "997462e2",
   "metadata": {},
   "source": [
    " <a id=\"one\"></a>\n",
    "## 1. Importing Packages\n",
    "<a href=#cont>Back to Table of Contents</a>\n",
    "\n",
    "---\n",
    "    \n",
    "| ⚡ Description: Importing Packages ⚡ |\n",
    "| :--------------------------- |\n",
    "| In this section we are importing, and briefly discussing, the libraries that will be used throughout the analysis and modelling. |\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e996e542",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install -U comet_ml unidecode nltk scikit-learn==0.24.2 contractions\n",
    "# %pip install emoji\n",
    "# %pip install pyspellchecker\n",
    "# %pip install ftfy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "068f4348",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import comet_ml at the top of your file\n",
    "from comet_ml import Experiment\n",
    "\n",
    "# probably should not leak the api key here... but in this context it's the easiest\n",
    "# remember to call experiment.end()\n",
    "def create_experiment():\n",
    "    return Experiment(\n",
    "        api_key='qyBYUW3bdXWZMKz3qXMeU6Dm4',\n",
    "        project_name='climate-change-tweet-classification',\n",
    "        workspace='thulaninyama',\n",
    "    )\n",
    "\n",
    "def log_results(experiment, params: dict, metrics: dict):\n",
    "    # Log our parameters and results\n",
    "    experiment.log_parameters(params)\n",
    "    experiment.log_metrics(metrics)\n",
    "\n",
    "# should not be used alone, use cometize_model instead\n",
    "def __record_run(experiment, params, y_true, y_pred):\n",
    "    metrics = {\n",
    "        \"accuracy\": accuracy_score(y_true, y_pred),\n",
    "        \"precision\": precision_score(y_true, y_pred, average='weighted'),\n",
    "        \"recall\": recall_score(y_true, y_pred, average='weighted'),\n",
    "        \"f1\": f1_score(y_true, y_pred, average='weighted'),\n",
    "    }\n",
    "    \n",
    "    log_results(experiment, params, metrics)\n",
    "    \n",
    "def cometize_model(model, _X, _y, notes='<no notes>', model_type='<not given>'):\n",
    "    exp = create_experiment()\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(_X, _y, test_size=0.20, shuffle=True, random_state=42)\n",
    "    mod = model.fit(X_train, y_train)\n",
    "    \n",
    "    y_pred = model.predict(X_test)\n",
    "    params = model.get_params(deep=True)\n",
    "    \n",
    "    exp.log_other(key=\"notes\", value=notes)\n",
    "    exp.log_other(key=\"model_type\", value=model_type)\n",
    "    \n",
    "    __record_run(exp, params, y_test, y_pred)\n",
    "        \n",
    "    exp.end()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "475dbe93",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-23T10:30:53.800892Z",
     "start_time": "2021-06-23T10:30:50.215449Z"
    }
   },
   "outputs": [],
   "source": [
    "# numpy is used to perform mathematical operations on arrays\n",
    "import numpy as np\n",
    "# pandas is used analyzing, cleaning, exploring, and data manipulation in dataframes.\n",
    "import pandas as pd\n",
    "from pandas import MultiIndex\n",
    "\n",
    "#Below are comprehensive libraries for creating static, animated, and interactive visualizations.\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import itertools\n",
    "import seaborn as sns\n",
    "from wordcloud import WordCloud\n",
    "from plotly import graph_objects as go\n",
    "# set plot style\n",
    "sns.set()\n",
    "#Regular Expression used for data cleaning\n",
    "import re\n",
    "\n",
    "#Text processing packages\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize, TreebankWordTokenizer\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import string\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "#Model evaluation packages\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report \n",
    "from sklearn.metrics import accuracy_score, precision_score,  recall_score\n",
    "\n",
    "#Packages to split the data for testing and training\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import f_classif\n",
    "\n",
    "#Modelling Packages\n",
    "from catboost import Pool, CatBoostClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from xgboost import XGBRFClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "#\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "# from imblearn.pipeline import make_pipeline\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.pipeline import FeatureUnion\n",
    "\n",
    "#Imbalanced data processing packages\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from collections import Counter\n",
    "from imblearn.combine import SMOTEENN, SMOTETomek\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdd7afb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# global constants\n",
    "random_state = 42\n",
    "from string import punctuation\n",
    "\n",
    "eng_stopword_set = set(stopwords.words('english'))\n",
    "punctuation_set = set([p for p in punctuation])\n",
    "\n",
    "print(\"Stopwords:\", len(eng_stopword_set))\n",
    "print(\"Punctuation:\", len(punctuation_set))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f22a6718",
   "metadata": {},
   "source": [
    "<a id=\"two\"></a>\n",
    "## 2. Loading the Data\n",
    "<a class=\"anchor\" id=\"1.1\"></a>\n",
    "<a href=#cont>Back to Table of Contents</a>\n",
    "\n",
    "---\n",
    "    \n",
    "| ⚡ Description: Loading the data ⚡ |\n",
    "| :--------------------------- |\n",
    "| In this section we are loading the data from the `df_train` file into a DataFrame. |\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee7d41a7",
   "metadata": {},
   "source": [
    "Below we connect and load publicly available train and test data set from TEAM-CW3 data repository to train and test Pandas dataframes respectively "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbbb6c18",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-28T08:49:35.311495Z",
     "start_time": "2021-06-28T08:49:35.295494Z"
    }
   },
   "outputs": [],
   "source": [
    "# connect and load train and test data sets\n",
    "df_train = pd.read_csv('https://raw.githubusercontent.com/TEAM-CW3/classification-predict-streamlit-data/main/train.csv') # load train data set\n",
    "df_test = pd.read_csv('https://raw.githubusercontent.com/TEAM-CW3/classification-predict-streamlit-data/main/test_with_no_labels.csv')  # load test data set\n",
    "df_train_copy = df_train.copy() # copy train data set"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81132ab3",
   "metadata": {},
   "source": [
    "<a id=\"three\"></a>\n",
    "## 3. Exploratory Data Analysis (EDA)\n",
    "<a class=\"anchor\" id=\"1.1\"></a>\n",
    "<a href=#cont>Back to Table of Contents</a>\n",
    "\n",
    "---\n",
    "    \n",
    "| ⚡ Description: Exploratory data analysis ⚡ |\n",
    "| :--------------------------- |\n",
    "| In this section, we are performing an in-depth analysis of all the variables in the DataFrame. |\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21fde79a",
   "metadata": {},
   "source": [
    "Below we visualize the train data set to see the features and the target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e805134e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-28T08:52:37.824204Z",
     "start_time": "2021-06-28T08:52:37.811206Z"
    }
   },
   "outputs": [],
   "source": [
    "# look at dataframe features\n",
    "df_train_copy.columns = [col.replace(\" \",\"_\") for col in df_train_copy.columns] # remove whitespace in feature names if any\n",
    "df_train_copy.head() # visualize train dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c0049a3",
   "metadata": {},
   "source": [
    "Below we look at the features, number of observations per feature and the data type of the features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91b253c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# look at data types of features\n",
    "df_train_copy.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2998cbf",
   "metadata": {},
   "source": [
    "Below we inspect statistics of features for each sentiment by looking at total count of observations, unique amount of observations and the most frequent observations for each sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa896750",
   "metadata": {},
   "outputs": [],
   "source": [
    "# look at statistics for non-numerical features\n",
    "df_train.groupby('sentiment').describe(include=['object']).T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32de8eb0",
   "metadata": {},
   "source": [
    "Below we inspect the number of rows and columns to view number of observations for each feature in the train data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16996d13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# look at number of columns and rows\n",
    "print('Number of columns: ', df_train_copy.shape[1])\n",
    "print('-------------------')\n",
    "print('Number of rows   : ', df_train_copy.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2143f1c9",
   "metadata": {},
   "source": [
    "Below we have a look at number data types collectively for all features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "544bdcb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# look at number of data types\n",
    "print('Count number columns per data type:')\n",
    "print('----------------------------------')\n",
    "print(df_train_copy.dtypes.value_counts())\n",
    "print('----------------------------------')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a09222a",
   "metadata": {},
   "source": [
    "Below we look for missing values in the train data set for every column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "752d7734",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot missing values in train set\n",
    "ax = df_train_copy.isna().sum().sort_values().plot(kind = 'barh', figsize = (9, 10), color='tab:red')\n",
    "plt.title('Percentage of Missing Values Per Column in Train Set', fontdict={'size':18})\n",
    "for p in ax.patches:\n",
    "    percentage ='{:,.0f}%'.format((p.get_width()/df_train.shape[0])*100, fontdict={'size':18})\n",
    "    width, height =p.get_width(),p.get_height()\n",
    "    x=p.get_x()+width+0.02\n",
    "    y=p.get_y()+height/2\n",
    "    ax.annotate(percentage,(x,y))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a54c82b2",
   "metadata": {},
   "source": [
    "Train data set has no empty values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2776091b",
   "metadata": {},
   "source": [
    "Below we analyze the distributions of the feature (Tweets) per sentiment (Positive, Negative, Neutral, News)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fb74182",
   "metadata": {},
   "outputs": [],
   "source": [
    "# distribution plots for sentiment\n",
    "fig,(ax1,ax2,ax3,ax4) = plt.subplots(1,4,figsize=(20,10))\n",
    "\n",
    "# positive\n",
    "sns.distplot(df_train_copy[df_train_copy['sentiment']==1]['message'].str.len(), hist=True, kde=True,\n",
    "             bins=int(200/25), color = 'red', \n",
    "             ax = ax1,\n",
    "             hist_kws={'edgecolor':'black'},\n",
    "             kde_kws={'linewidth': 4}) # set line graph pixels\n",
    "ax1.set_title('Positive') # set graph title\n",
    "ax1.set_xlabel('Message Length') # label the x-axis\n",
    "ax1.set_ylabel('Density') # label the y-axis\n",
    "\n",
    "# negative \n",
    "sns.distplot(df_train_copy[df_train_copy['sentiment']==-1]['message'].str.len(), hist=True, kde=True,\n",
    "             bins=int(200/25), color = 'black', \n",
    "             ax = ax2,\n",
    "             hist_kws={'edgecolor':'black'},\n",
    "             kde_kws={'linewidth': 4}) # set line graph pixels\n",
    "ax2.set_title('Negative ') # set graph title\n",
    "ax2.set_xlabel('Message Length') # label the x-axis\n",
    "ax2.set_ylabel('Density') # label the y-axis\n",
    "\n",
    "# neutral \n",
    "sns.distplot(df_train_copy[df_train_copy['sentiment']==0]['message'].str.len(), hist=True, kde=True,\n",
    "             bins=int(200/25), color = 'yellow',  \n",
    "             ax = ax3,\n",
    "             hist_kws={'edgecolor':'black'},\n",
    "             kde_kws={'linewidth': 4}) # set line graph pixels\n",
    "ax3.set_title('Neutral ') # set graph title\n",
    "ax3.set_xlabel('Message Length') # label the x-axis\n",
    "ax3.set_ylabel('Density') # label the y-axis\n",
    "\n",
    "# news\n",
    "sns.distplot(df_train_copy[df_train_copy['sentiment']==2]['message'].str.len(), hist=True, kde=True,\n",
    "             bins=int(200/25), color = 'blue', \n",
    "             ax = ax4,\n",
    "             hist_kws={'edgecolor':'black'},\n",
    "             kde_kws={'linewidth': 4}) # set line graph pixels\n",
    "ax4.set_title('News') # set graph title\n",
    "ax4.set_xlabel('Message Length') # label the x-axis\n",
    "ax4.set_ylabel('Density')  # label the y-axis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "966ab5b4",
   "metadata": {},
   "source": [
    "By observing the graphs you can see that the average length for all opinions is relatively the same, this may be due to that every tweet has a word limit. However when we comparing the density between negative and positive sentiments there is noticable difference. We will do more analysis to figure out what needs to be done at sentimental analysis stage.\n",
    "\n",
    "Color Key :\n",
    "\n",
    "- Red     : Positive\n",
    "- Black   : Negative\n",
    "- Neutral : Yellow\n",
    "- Blue    : News"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a12ad0bc",
   "metadata": {},
   "source": [
    "Below we look at the unique values of the sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1544727a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# look at unique values in the columns that have object data type\n",
    "print('Unique values in \\'Sentiment\\' column: ' + str(df_train_copy.sentiment.unique()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7219c459",
   "metadata": {},
   "source": [
    "With the amount of unique values we can see that we have multi-class labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2d73662",
   "metadata": {},
   "source": [
    "Below we have a look at feature distributions of observations by sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de51df85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# have a look at feature distributions\n",
    "print(\"Distribution of messages per sentiment : \")\n",
    "count = df_train_copy.groupby(\"sentiment\").count()[\"message\"].reset_index().sort_values(by=\"message\", ascending=False)\n",
    "count.style.background_gradient(cmap=\"Reds\")\n",
    "# df_train_copy.set_index(\"sentiment\", inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb9ddfef",
   "metadata": {},
   "source": [
    "Analysis proof is as follows:\n",
    "\n",
    "- 1 Positive tweets: there is 8530 tweets that support the belief of man-made climate changes.\n",
    "\n",
    "- -1 Negative tweets: there is 1296 tweets that does not support the believe in man-made climate changes.\n",
    "\n",
    "- 0 Neutral tweets: there 2353 tweets that neither support nor refute the belief of man-made climate changes.\n",
    "\n",
    "- 2 News tweets: there 3640 tweets that link to factual news about climate changes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f108f2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "working_df = df_train_copy\n",
    "# labeling the target\n",
    "working_df['sentiment'] = [['Negative', 'Neutral', 'Positive', 'News'][x+1] for x in working_df['sentiment']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a001b051",
   "metadata": {},
   "source": [
    "Below we look at the percentage of messages per sentiment out of the total message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ce0af37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# observing numerical distribution\n",
    "values = working_df['sentiment'].value_counts()/working_df.shape[0]\n",
    "labels = (working_df['sentiment'].value_counts()/working_df.shape[0]).index\n",
    "colors = ['red', 'green', 'yellow', 'blue']\n",
    "plt.pie(x=values, labels=labels, autopct='%1.1f%%', startangle=90, explode=(0.03, 0, 0, 0), colors=colors)\n",
    "plt.show(20,20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b65dd714",
   "metadata": {},
   "source": [
    "The train data set consists of an uneven percentage of data distribution between the sentiment classification values.\n",
    "\n",
    "- Positive tweets consists of 53.92% of the total tweets.\n",
    "\n",
    "- Negative tweets consists of 8.19% of the total tweets.\n",
    "\n",
    "- Neutral tweets consists 14.87% of the total tweets.\n",
    "\n",
    "- News tweets consists 23.02% of the total tweets.\n",
    "\n",
    "After observing our Pie-Chart above you can see than more than half of the sample tweets come from positive sentiments, tweets from sentiment that do not believe in man-made climate change are the least and News are the second most popular."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ca14929",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_text = ' '.join(df_train_copy['message'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b1de426",
   "metadata": {},
   "outputs": [],
   "source": [
    "wc = WordCloud(background_color='white')\n",
    "img = wc.generate(full_text)\n",
    "plt.figure(figsize=(20,10))\n",
    "plt.imshow(img)\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64729295",
   "metadata": {},
   "outputs": [],
   "source": [
    "gb = df_train.groupby('sentiment') # get the groupby object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a29240c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "Positive = ''.join(gb.get_group(1)['message']) # extract messages from the positive sentiment\n",
    "Negative = ''.join(gb.get_group(-1)['message']) # extract messages from the negative sentiment\n",
    "Neutral = ''.join(gb.get_group(0)['message']) # extract messages from the neutral sentiment\n",
    "News = ''.join(gb.get_group(2)['message']) # extract messages from the news sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4884d3ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "wc = WordCloud(background_color='red')\n",
    "img = wc.generate(Positive)\n",
    "plt.figure(figsize=(20,10))\n",
    "plt.imshow(img)\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93ed0baf",
   "metadata": {},
   "source": [
    "gb = df_train.groupby('sentiment')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ba4d9bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "wc = WordCloud(background_color='blue')\n",
    "img = wc.generate(Negative)\n",
    "plt.figure(figsize=(20,10))\n",
    "plt.imshow(img)\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77b1cbe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "wc = WordCloud(background_color='yellow')\n",
    "img = wc.generate(Neutral)\n",
    "plt.figure(figsize=(20,10))\n",
    "plt.imshow(img)\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d0a3e75",
   "metadata": {},
   "outputs": [],
   "source": [
    "wc = WordCloud(background_color='green')\n",
    "img = wc.generate(News)\n",
    "plt.figure(figsize=(20,10))\n",
    "plt.imshow(img)\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fa93ec6",
   "metadata": {},
   "source": [
    "<a id=\"four\"></a>\n",
    "## 4. Sentiment Analysis\n",
    "<a class=\"anchor\" id=\"1.1\"></a>\n",
    "<a href=#cont>Back to Table of Contents</a>\n",
    "\n",
    "---\n",
    "    \n",
    "| ⚡ Description: Sentiment Analysis ⚡ |\n",
    "| :--------------------------- |\n",
    "| In this section we do sentiment analysis, and possibly create new features - as identified in the EDA phase. |\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a9acca2",
   "metadata": {},
   "outputs": [],
   "source": [
    "stem = df_train['message']\n",
    "stem_vectrz = CountVectorizer(ngram_range=(1, 2), min_df=5, max_df=0.5)\n",
    "stem_msg_vec = stem_vectrz.fit_transform(stem)\n",
    "print('Numner of features in [stem]:', len(stem_vectrz.get_feature_names()))\n",
    "X_stem = stem_msg_vec\n",
    "y = df_train['sentiment']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f365b64",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_stem, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43b2d523",
   "metadata": {},
   "source": [
    "<a id=\"five\"></a>\n",
    "## 5. Modelling\n",
    "<a class=\"anchor\" id=\"1.1\"></a>\n",
    "<a href=#cont>Back to Table of Contents</a>\n",
    "\n",
    "---\n",
    "    \n",
    "| ⚡ Description: Modelling ⚡ |\n",
    "| :--------------------------- |\n",
    "| In this section, we create one or more classification models that are able to accurately classify if people believe in climate change or not. |\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3200e66f",
   "metadata": {},
   "outputs": [],
   "source": [
    "SW_uni = SVC(C = 0.1, degree = 1, kernel = 'linear')\n",
    "SW_uni.fit(X_train,y_train)\n",
    "y_pred = SW_uni.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1330784",
   "metadata": {},
   "outputs": [],
   "source": [
    "LFC = LogisticRegression()\n",
    "LFC.fit(X_train,y_train)\n",
    "y_pred = LFC.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09669588",
   "metadata": {},
   "outputs": [],
   "source": [
    "RFC = RandomForestClassifier() \n",
    "RFC.fit(X_train,y_train)\n",
    "y_pred = RFC.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08bafbe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "LSC = LinearSVC(C=0.1, class_weight='balanced',max_iter=1800)\n",
    "LSC.fit(X_train,y_train)\n",
    "y_pred = LSC.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8615b584",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "clfs = GradientBoostingClassifier()\n",
    "clfs.fit(X_train,y_train)\n",
    "y_pred = clfs.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaa424b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "cl = AdaBoostClassifier()\n",
    "cl.fit(X_train,y_train)\n",
    "y_pred = cl.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "938d0500",
   "metadata": {},
   "outputs": [],
   "source": [
    "import catboost\n",
    "from catboost import CatBoostClassifier\n",
    "CBC = CatBoostClassifier(depth= 9,iterations = 30,learning_rate= 0.01)\n",
    "CBC.fit(X_train,y_train)\n",
    "y_pred = CBC.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2a80f7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import StackingClassifier\n",
    "sc = StackingClassifier(\n",
    "    estimators=[  \n",
    "        ('LSC', LSC), \n",
    "        ('LFC', LFC),\n",
    "        ('SW_uni', SW_uni)\n",
    "    ],\n",
    "    final_estimator=CBC,\n",
    "    n_jobs=1,\n",
    "    passthrough=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a85889f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.fit(X_train,y_train)\n",
    "y_pred = sc.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b66466b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(df: pd.DataFrame):\n",
    "    return stem_vectrz.transform(df['message'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "227c1f2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_submission(model, pred_X):\n",
    "    y_pred = model.predict(pred_X) # prediction\n",
    "    submission = { # submission\n",
    "        \"tweetid\": df_test['tweetid'].values,\n",
    "        \"sentiment\": y_pred,\n",
    "    }\n",
    "    return pd.DataFrame(submission).set_index('tweetid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fd15d45",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_X = preprocess(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e824b02b",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b9e0762",
   "metadata": {},
   "outputs": [],
   "source": [
    "submit_df = generate_submission(sc, pred_X)\n",
    "submit_df.to_csv('SC.csv')\n",
    "print(\"Submission Generated\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a05304d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pickle\n",
    "\n",
    "# model_save_path = \"CW3.pkl\"\n",
    "# with open(model_save_path,'wb') as file:\n",
    "#     pickle.dump(CW3,file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b530251",
   "metadata": {},
   "source": [
    "<a id=\"six\"></a>\n",
    "## 6. Model Performance\n",
    "<a class=\"anchor\" id=\"1.1\"></a>\n",
    "<a href=#cont>Back to Table of Contents</a>\n",
    "\n",
    "---\n",
    "    \n",
    "| ⚡ Description: Model performance ⚡ |\n",
    "| :--------------------------- |\n",
    "| In this section you are required to compare the relative performance of the various trained ML models on a holdout dataset and comment on what model is the best and why. |\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a69b5a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare model performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3874a7c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose best model and motivate why it is the best choice"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8ad0c0d",
   "metadata": {},
   "source": [
    "<a id=\"seven\"></a>\n",
    "## 7. Model Explanations\n",
    "<a class=\"anchor\" id=\"1.1\"></a>\n",
    "<a href=#cont>Back to Table of Contents</a>\n",
    "\n",
    "---\n",
    "    \n",
    "| ⚡ Description: Model explanation ⚡ |\n",
    "| :--------------------------- |\n",
    "| In this section, you are required to discuss how the best performing model works in a simple way so that both technical and non-technical stakeholders can grasp the intuition behind the model's inner workings. |\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ff741c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# discuss chosen methods logic"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "856a8449caac1f0f5343e6ebd97025a3528b37a835414937152ef42ed43f001e"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
